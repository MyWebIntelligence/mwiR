% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/recode.R
\name{mwir_seorank}
\alias{mwir_seorank}
\title{Fetch SEO Rank Data for URLs}
\usage{
mwir_seorank(
  filename = NULL,
  urls = NULL,
  api_key = NULL,
  parallel = TRUE,
  workers = NULL,
  progress = TRUE,
  rate_limit_delay = 0.2
)
}
\arguments{
\item{filename}{A character string specifying the name of the output CSV file
(without extension). If NULL, the function will stop and prompt for input.}

\item{urls}{A character vector of URLs to fetch SEO rank data for. If NULL,
the function will stop and prompt for input.}

\item{api_key}{A character string containing the API key for the SEO Rank API.
If NULL, the function will stop and prompt for input.}

\item{parallel}{Logical. If TRUE (default), use parallel processing with multiple
workers. Set to FALSE for sequential processing.}

\item{workers}{Integer. Number of parallel workers. If NULL (default), uses
`availableCores() - 1`. Ignored if `parallel = FALSE`.}

\item{progress}{Logical. If TRUE (default), display a progress bar.}

\item{rate_limit_delay}{Numeric. Delay in seconds between API calls (default 0.2).
Used only in sequential mode; parallel mode relies on natural distribution.}
}
\value{
Invisibly returns a data frame with all fetched data. Also writes the
  results to a CSV file.
}
\description{
This function retrieves SEO rank data for a list of URLs using the SEO Rank API
and writes the results to a CSV file. Supports parallel processing for faster
execution on large URL lists.
}
\details{
The function supports two processing modes:
\itemize{
  \item \strong{Parallel mode} (default): Uses `future` and `furrr` packages to
    process multiple URLs simultaneously. Significantly faster for large URL lists.
  \item \strong{Sequential mode}: Processes URLs one at a time with configurable
    delay between requests.
}

Results are written to CSV in a single batch operation after all URLs are processed,
which is more efficient than row-by-row writing.
}
\note{
This function requires an active internet connection and a valid API key from
https://seo-rank.my-addr.com/.
}
\examples{
\dontrun{
# Parallel fetch (default, fastest)
mwir_seorank("my_seo_data", c("example.com", "example.org"), "YOUR_API_KEY")

# Sequential fetch with progress
mwir_seorank("my_seo_data", urls, "YOUR_API_KEY", parallel = FALSE)

# Parallel with custom worker count
mwir_seorank("my_seo_data", urls, "YOUR_API_KEY", workers = 4)
}

}
