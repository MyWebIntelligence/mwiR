% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/crawl.R, R/land.R
\name{phrase_tokenizer}
\alias{phrase_tokenizer}
\title{Tokenize Phrases by Splitting on Commas}
\usage{
phrase_tokenizer(text)
}
\arguments{
\item{text}{A character string containing the phrase or text to be tokenized.}
}
\value{
Returns a character vector containing the individual tokens obtained by splitting the input text on commas.
}
\description{
This function takes a phrase or text string and splits it into individual tokens based on commas. It is useful for parsing lists or comma-separated values into discrete elements for further processing.
}
\details{
The function processes the input text by using commas as delimiters to separate and extract tokens. Whitespace around tokens is typically trimmed.
}
\examples{
\dontrun{
# Tokenize a comma-separated phrase
phrase_tokenizer("term1, term2, term3")
}
}
